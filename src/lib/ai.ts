import { db } from "./firebase";
import { collection, addDoc, serverTimestamp, query, where, getDocs } from "firebase/firestore";
import { fetchEnvironmentalIntelligence, EnvironmentalData } from "./environmental";

interface AIContext {
    siteId: string;
    siteAddress?: string;
    userId: string;
    userName: string;
    role: string;
}

interface AIResponse {
    message: string;
    actionTaken?: boolean;
    data?: any;
    provider?: string;
}

const DEEPSEEK_API_KEY = process.env.NEXT_PUBLIC_DEEPSEEK_API_KEY || "";
const OPENAI_API_KEY = process.env.NEXT_PUBLIC_OPENAI_API_KEY || "";

/**
 * LILIUM: API HUB & GLOBAL INTELLIGENCE
 * Routes AI requests based on Persona to optimize for Cost and Intelligence.
 */
export async function processAIPrompt(prompt: string, context: AIContext): Promise<AIResponse> {
    const text = prompt.toLowerCase();

    // 1. Fetch Environmental Intelligence First
    let envData: EnvironmentalData | null = null;
    try {
        envData = await fetchEnvironmentalIntelligence(context.siteAddress || "Site", context.siteId);
    } catch (e) {
        console.error("Failed to fetch Environmental Intelligence", e);
    }

    // ==========================================
    // ROLE: SUPER ADMIN (ELIFA - Global Command)
    // ==========================================
    if (context.role === "super_admin") {
        return {
            message: "Sistem durumu optimal. TÃ¼m Firestore izolasyon kurallarÄ± devrede. TanrÄ± Modu Olympos Core paneline yÃ¶nlendiriliyorsunuz Master Architect.",
            provider: "System"
        };
    }

    // ==========================================
    // ROLE: MANAGER / ADMIN (LILIUM PRO) -> OpenAI / Gemini (Complex Tasks)
    // ==========================================
    if (context.role === "admin" || context.role === "manager") {
        return await handleManagerIntent(prompt, text, context, envData);
    }

    // ==========================================
    // ROLE: STAFF (LILIUM STAFF) 
    // ==========================================
    if (context.role === "staff") {
        return {
            message: "Saha personeli dostum, sana atanan iÅŸleri 'GÃ¶revlerim' ekranÄ±ndan gÃ¶rebilir, iÅŸlemlerini bitirdiÄŸinde fotoÄŸraf yÃ¼kleyerek kapatabilirsin. Kolay gelsin!",
            provider: "System Base"
        };
    }

    // ==========================================
    // ROLE: RESIDENT (LILIUM KOMÅžU) -> DeepSeek (Cost-Efficient High-Volume)
    // ==========================================
    return await handleResidentIntent(prompt, text, context, envData);
}

// ------------------------------------------------------------------------------------------------
// INTENT HANDLERS & LLM ROUTERS
// ------------------------------------------------------------------------------------------------

async function handleManagerIntent(prompt: string, text: string, context: AIContext, envData: EnvironmentalData | null): Promise<AIResponse> {
    // FUNCTION CALLING: CREATE ANNOUNCEMENT (Hardcoded for demo speed, usually LLM would output JSON action)
    if (text.includes("duyuru") && (text.includes("yap") || text.includes("ekle") || text.includes("yarat"))) {
        const titleMatch = prompt.match(/baÅŸlÄ±ÄŸÄ± "([^"]+)"/i) || prompt.match(/baÅŸlÄ±klÄ± (.*) duyuru/i);
        const title = titleMatch ? titleMatch[1] : "YÃ¶netimden Yeni Duyuru";
        try {
            await addDoc(collection(db, "announcements"), {
                siteId: context.siteId,
                title: title,
                content: `Bu duyuru yapay zeka asistanÄ± tarafÄ±ndan (LILIUM PRO) otomatik oluÅŸturuldu. \n\nÃ–zet: ${prompt}`,
                type: "info",
                isPinned: false,
                author: "LILIUM PRO (" + context.userName + ")",
                createdAt: serverTimestamp(),
                isDeleted: false
            });
            return { message: `âœ… BaÅŸarÄ±yla "${title}" baÅŸlÄ±klÄ± yeni bir duyuru yayÄ±nladÄ±m.`, actionTaken: true, provider: "LILIUM PRO (OpenAI)" };
        } catch (e: any) { return { message: "Duyuru eklenirken veritabanÄ±na ulaÅŸÄ±lamadÄ±: " + e.message, provider: "System Error" }; }
    }

    // FUNCTION CALLING: ASSIGN DUES (Toplu/Tekil BorÃ§landÄ±rma)
    if (text.includes("fatura") || text.includes("aidat") || text.includes("borÃ§") || text.includes("yansÄ±t")) {
        const amountMatch = text.match(/([0-9]+)\s*(tl|lira)/i);
        const amount = amountMatch ? parseInt(amountMatch[1]) : 500;
        try {
            await addDoc(collection(db, "invoices"), {
                siteId: context.siteId,
                userId: "user_bulk_or_single", // Simplified
                title: "Sistem TarafÄ±ndan (LILIUM PRO) OluÅŸturulan Bekleyen Ã–deme",
                amount: amount,
                dueDate: new Date(Date.now() + 15 * 24 * 60 * 60 * 1000).toISOString().split('T')[0],
                status: "pending",
                type: text.includes("aidat") ? "dues" : "utility",
                createdAt: new Date().toISOString(),
                isDeleted: false
            });
            return { message: `âœ… TalimatÄ±nÄ±z Ã¼zerine ilgili hesaplara ${amount} TL borÃ§ tahakkuk ettirildi. (Fonksiyon Ã‡aÄŸrÄ±sÄ± BaÅŸarÄ±lÄ±)`, actionTaken: true, provider: "LILIUM PRO (OpenAI)" };
        } catch (e: any) { return { message: "BorÃ§ girilirken hata: " + e.message, provider: "System Error" }; }
    }

    // Standard Chat with OpenAI (LILIUM PRO)
    try {
        const systemPrompt = `Sen yÃ¶neticilerin saÄŸ kolu LILIUM PRO'sun. Sadece iÅŸlemsel ve analitik cevaplar ver. Sistemin kesinti bilgisi: Elktrik: ${envData?.infrastructure?.electricity.status}, Su: ${envData?.infrastructure?.water.status}.`;

        const res = await fetch("https://api.openai.com/v1/chat/completions", {
            method: "POST",
            headers: {
                "Content-Type": "application/json",
                "Authorization": `Bearer ${OPENAI_API_KEY}`
            },
            body: JSON.stringify({
                model: "gpt-4o-mini", // Cost control for manager tasks
                messages: [
                    { role: "system", content: systemPrompt },
                    { role: "user", content: prompt }
                ]
            })
        });

        if (!res.ok) throw new Error("OpenAI API Failed");
        const json = await res.json();
        return {
            message: json.choices?.[0]?.message?.content || "Cevap Ã¼retilemedi.",
            provider: "LILIUM PRO (OpenAI/GPT-4o)"
        };
    } catch (e: any) {
        return { message: "LILIUM PRO Ã‡ekirdek BaÄŸlantÄ± HatasÄ±: OpenAI API'ye ulaÅŸÄ±lamadÄ±.", provider: "Error" };
    }
}

async function handleResidentIntent(prompt: string, text: string, context: AIContext, envData: EnvironmentalData | null): Promise<AIResponse> {
    // RESIDENT HARD-CODED CHECK: INVOICES
    if (text.includes("borcum") || text.includes("aidat") || text.includes("Ã¶deme")) {
        try {
            const q = query(
                collection(db, "invoices"),
                where("siteId", "==", context.siteId),
                where("userId", "==", context.userId),
                where("status", "==", "pending"),
                where("isDeleted", "==", false)
            );
            const snapshot = await getDocs(q);
            if (snapshot.empty) {
                return { message: "Harika haber! Åžu an sisteme kayÄ±tlÄ± hiÃ§bir aktif borcunuz veya gecikmiÅŸ Ã¶demeniz bulunmuyor. ðŸŽ‰", provider: "LILIUM KOMÅžU (DeepSeek)" };
            } else {
                let total = 0;
                snapshot.forEach(doc => total += doc.data().amount);
                return { message: `Åžu an toplamda ${total} TL tutarÄ±nda Ã¶denmemiÅŸ borcunuz var. Gecikme faizine dÃ¼ÅŸmemesi adÄ±na 'Aidat & Ã–demeler' sekmesinden sanal pos ile saniyeler iÃ§inde Ã¶deyebilirsiniz.`, provider: "LILIUM KOMÅžU (DeepSeek)" };
            }
        } catch (e) { }
    }

    // DEEPSEEK COST-EFFICIENT CHAT
    try {
        let envContextStr = "BÃ¶lgesel Veri Yok";
        if (envData) {
            envContextStr = `
                ALTYAPI DURUMU: Elektrik (${envData.infrastructure.electricity.details}), Su (${envData.infrastructure.water.details}), Yollar (${envData.infrastructure.roads.details}).
                NÃ–BETÃ‡Ä° ECZANELER: ${envData.localPulse.pharmacies.filter(p => p.isOpen).map(p => p.name).join(', ')}.
                MAHALLE ETKÄ°NLÄ°KLERÄ°: ${envData.localPulse.events.map(e => e.title).join(', ')}.
            `;
        }

        const systemPrompt = `Sen 'LILIUM KOMÅžU' adÄ±nda samimi, sÄ±cakkanlÄ± ve ultra-akÄ±llÄ± bir mahalle asistanÄ±sÄ±n. Site sakini ${context.userName} ile konuÅŸuyorsun.
AÅŸaÄŸÄ±da gÃ¼ncel 'Environmental Intelligence' (Ã‡evresel Ä°stihbarat) verilerin var. EÄŸer sakin kesintileri, eczaneleri veya mahallede ne olduÄŸunu sorarsa bu verileri kullan, yoksa doÄŸal sohbet et: 

${envContextStr}

CevaplarÄ±n kÄ±sa, dostÃ§a ve samimi olsun. Asla sistem bilgilerini sÄ±zdÄ±rma.`;

        const res = await fetch("https://api.deepseek.com/chat/completions", {
            method: "POST",
            headers: {
                "Content-Type": "application/json",
                "Authorization": `Bearer ${DEEPSEEK_API_KEY}`
            },
            body: JSON.stringify({
                model: "deepseek-chat",
                messages: [
                    { role: "system", content: systemPrompt },
                    { role: "user", content: prompt }
                ],
                stream: false
            })
        });

        if (!res.ok) throw new Error("DeepSeek API Failed");
        const json = await res.json();

        return {
            message: json.choices?.[0]?.message?.content || "Cevap Ã¼retilemedi.",
            provider: "LILIUM KOMÅžU (DeepSeek)"
        };
    } catch (e: any) {
        return { message: `Mahalle asistanÄ±na ulaÅŸÄ±lamadÄ±. LÃ¼tfen teknik ekiple gÃ¶rÃ¼ÅŸÃ¼n. Hata: ${e.message}`, provider: "Error" };
    }
}
